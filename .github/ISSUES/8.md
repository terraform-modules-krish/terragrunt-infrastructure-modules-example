# How is automated testing handled in a multi-module repository?

**tillig** commented *Nov 26, 2019*

Let's say I have a "live modules" repository like this with multiple individual modules referenced by the "live repository." What's the recommendation for how to handle something like this in a CI/automated testing pipeline?

I can see a few options:
- Run all the tests and validation for every module in the repo on every push. Depending on how many modules are in the repo, this could take a very, very long time. Maybe that's OK.
- Create separate CI pipelines for each module using some sort of "path filtering" mechanism built into your CI server. This would be faster, but would also potentially have a lot of pipelines depending on how many modules are in the repo.
- Only do manual kickoff of a CI build. Require some sort of input parameter to indicate, say, the path of the component that changed.
- Do some fairly extravagant magic to try to determine what commits have shown up since the last build, which files in those commits changed, and, from that, infer which module(s) need to be tested.

I noticed [on this issue](https://github.com/gruntwork-io/terragrunt/issues/720#issuecomment-497888756) it sounded like CI was an area being worked on. Not a huge deal if there's no specific recommendation, but I'm sort of working on this now myself and am struggling to balance number of pipelines with speed of feedback.
<br />
***


**brikis98** commented *Nov 27, 2019*

This is indeed an area that's not well developed in the Terraform world. What you're really looking for is a proper _dependency management system_. E.g., In Java, you can use Maven or Gradle; in Ruby, you use Gems; in JavaScript, you use Yarn or NPM. If in the `infrastructure-modules` repo, any given folder `foo` could only depend on code directly in that folder, or dependencies _explicitly_ defined in some file (e.g., `dependencies.hcl`), then for each commit, you could tell exactly what tests to run. Without such a dependency manager, all you're left with are the options you listed. Most companies I've seen currently rely on (a) heuristics or (b) allowing devs to specify which tests to run as part of a commit message.
***

**tillig** commented *Nov 27, 2019*

The commit message thing isn't something I considered, that might be an area to follow up on.

My change detection magic was going to involve [the CI server (Azure DevOps) making a REST call](https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/utility/http-rest-api?view=azure-devops) to the [CI server's own API for builds](https://docs.microsoft.com/en-us/rest/api/azure/devops/build/builds/get%20changes%20between%20builds?view=azure-devops-rest-5.1) to determine the changesets that have been added since the last build (e.g., if someone had multiple commits and one push). I could use those commit hashes along with [`git diff-tree`](https://git-scm.com/docs/git-diff-tree) to list the files that changed, then infer from file paths what actually changed and test only the changed modules.

But... wow. That seems complex at best.

Is this sort of thing potentially a reason to _not_ use a "live module repository" and instead have each live module in its own repo? Since ostensibly each module in a repo like this one is an independent thing, "releases" get tagged just like generic modules, and "upgrading" in the live repo is effectively switching tags... it seems like the questions of "what changed?" and "what do I test?" might be more easily answered if you never had a repo like this one where multiple modules reside. It's more repos and pipelines, but maybe that's OK.

**Is there any sort of compelling reason to treat a set of "live modules" differently from a generic module and have all the live modules in the same repo?**

If not, it would mean you could have a standard CI pipeline for _all_ module types - generic or live - and the live repository is where all that would come together. Which... that's sort of where it comes together already, right?
***

**tillig** commented *Nov 27, 2019*

Perhaps related: I gather that in generic modules you should pin a _range_ of Terraform supported versions (`required_version = ">= 0.12.0"`) but in a live repo / live modules you should pin a _specific_ Terraform version (`required_version = ">= 0.12.16") to avoid accidental deployment using an earlier version or otherwise corrupting the state file.

If that's the case, hypothetically every live module could specify its own fixed version of Terraform, which would make the testing scenario challenging if you have several different versions pinned across the repo and need to run tests against all the modules. That would make the one-module-per-repo pattern more compelling - one module, one repo, one fixed version of Terraform (and possibly also pinned versions of the providers).

I did notice that the example modules in this live repo don't pin specific versions of Terraform or providers; and the live repo itself also doesn't pin those versions. Is that intentional?
***

**brikis98** commented *Nov 29, 2019*

> Is there any sort of compelling reason to treat a set of "live modules" differently from a generic module and have all the live modules in the same repo?

This isn't an issue specific to Terraform or the live modules or anything else. It's the standard mono-repo vs multi-repo trade-offs. Mono-repo has a bunch of nice properties, but requires a much larger investment in tooling: especially 1st class dependency management. Multi-repo is a way to get dependency management without having to build any new tooling; you are using the repos themselves as your dependency management tool. That has some pros and some cons: e.g., easier to get started, but harder to scale (more repos to manage, more pipelines to manage, harder to search across repos, harder to make global changes across many repos, etc).

> Perhaps related: I gather that in generic modules you should pin a range of Terraform supported versions (required_version = ">= 0.12.0") but in a live repo / live modules you should pin a specific Terraform version (`required_version = ">= 0.12.16") to avoid accidental deployment using an earlier version or otherwise corrupting the state file.

Yep.

> If that's the case, hypothetically every live module could specify its own fixed version of Terraform, which would make the testing scenario challenging if you have several different versions pinned across the repo and need to run tests against all the modules. That would make the one-module-per-repo pattern more compelling - one module, one repo, one fixed version of Terraform (and possibly also pinned versions of the providers).

Again, this is a dependency management question. Proper tooling would allow you to define Terraform versions on a per-folder basis; without such tooling, you are using the repo itself to define those versions.

> I did notice that the example modules in this live repo don't pin specific versions of Terraform or providers; and the live repo itself also doesn't pin those versions. Is that intentional?

The examples in these repos do not show all possible features/combinations/etc. PRs welcome!
***

**tillig** commented *Dec 2, 2019*

> This isn't an issue specific to Terraform or the live modules or anything else. It's the standard mono-repo vs multi-repo trade-offs.

This is good to know. Reading through the book (second edition) it isn't clear that the structure of the live repo being illustrated this way is a 'monorepo vs. polyrepo' choice.

For context on my thought process, as you read through the _Terraform: Up & Running_ book the reasons things are structured the way they are don't always become immediately clear, but after reading further it's like, "Oh! I get it! That makes sense!" The chosen structure of the example live repo / live modules in there didn't get quite the explanation so I assumed I was missing something.

No problem, this helps clear things up a lot. Likely due to tooling my team will go polyrepo.

I'll see about a PR for pinning the Terraform / provider versions here to make them consistent with the guidance in the book; and maybe one for the README to explain monorepo vs. polyrepo.

Thanks again!
***

